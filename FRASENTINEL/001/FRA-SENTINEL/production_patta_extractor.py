#!/usr/bin/env python3
"""
Production Tamil+English Patta Document Extractor
Integrates expert parsing with OCR processing
"""

import re, os, json
import pdfplumber
from pdf2image import convert_from_path
import pytesseract
import logging
from datetime import datetime
from typing import Dict

# Configure Tesseract path
pytesseract.pytesseract.tesseract_cmd = r'C:\Program Files\Tesseract-OCR\tesseract.exe'

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class ProductionPattaExtractor:
    """Production-ready Tamil+English Patta Document Extractor"""
    
    def __init__(self):
        self.field_patterns = {
            'owner_name': [
                # Direct Tamil Nadu patterns
                r'(‡Æá‡Æ∞‡Ææ‡ÆÆ‡Æö‡Øç‡Æö‡Æ®‡Øç‡Æ§‡Æø‡Æ∞‡Æ©‡Øç\s*‡ÆÆ‡Æ©‡Øà‡Æµ‡Æø\s*‡ÆÜ‡Æ©‡Æ®‡Øç‡Æ§‡Æ™‡Æø‡Æ∞‡Æø‡ÆØ‡Ææ)',
                r'(?:‡Æâ‡Æ∞‡Æø‡ÆÆ‡Øà‡ÆØ‡Ææ‡Æ≥‡Æ∞‡Øç‡Æï‡Æ≥‡Øç\s*‡Æ™‡ØÜ‡ÆØ‡Æ∞‡Øç)\s*[:\-‚Äì]?\s*([A-Za-z‡ÆÖ-‡Æπ\s\.]+)',
                r'(?:‡Æâ‡Æ∞‡Æø‡ÆÆ‡Øà‡ÆØ‡Ææ‡Æ≥‡Æ∞‡Øç\s*‡Æ™‡ØÜ‡ÆØ‡Æ∞‡Øç)\s*[:\-‚Äì]?\s*([A-Za-z‡ÆÖ-‡Æπ\s\.]+)',
                r'(?:‡Æ™‡ØÜ‡ÆØ‡Æ∞‡Øç|‡Æ™\s*‡ÆØ\s*‡Æ∞\s*)\s*[:\-‚Äì]?\s*([A-Za-z‡ÆÖ-‡Æπ\s\.]+)',
                r'(?:Owner\s*Name|Name\s*of\s*Owner)\s*[:\-‚Äì]?\s*([A-Za-z‡ÆÖ-‡Æπ\s\.]+)'
            ],
            'father_or_husband': [
                # Direct Tamil Nadu patterns
                r'(‡ÆÆ‡Æ©‡Øà‡Æµ‡Æø\s*‡ÆÜ‡Æ©‡Æ®‡Øç‡Æ§‡Æ™‡Æø‡Æ∞‡Æø‡ÆØ‡Ææ)',
                r'(?:‡Æ§‡Æ®‡Øç‡Æ§‡Øà|‡Æï‡Æ£‡Æµ‡Æ∞‡Øç|‡ÆÆ‡Æ©‡Øà‡Æµ‡Æø)\s*[:\-‚Äì]?\s*([A-Za-z‡ÆÖ-‡Æπ\s\.]+)',
                r'(?:‡Æ§\s*‡Æ®\s*‡Æ§\s*‡Øà|‡Æï\s*‡Æ£\s*‡Æµ\s*‡Æ∞\s*|‡ÆÆ\s*‡Æ©\s*‡Øà\s*‡Æµ\s*‡Æø\s*)\s*[:\-‚Äì]?\s*([A-Za-z‡ÆÖ-‡Æπ\s\.]+)',
                r'(?:Father|Husband|Wife)\s*[:\-‚Äì]?\s*([A-Za-z‡ÆÖ-‡Æπ\s\.]+)'
            ],
            'patta_no': [
                # Direct Tamil Nadu patterns
                r'(?:‡Æ™‡Æü‡Øç‡Æü‡Ææ\s*‡Æé‡Æ£‡Øç\s*[:\-‚Äì]?\s*366)',
                r'(?:‡Æ™‡Æü‡Øç‡Æü‡Ææ\s*‡Æé‡Æ£‡Øç\s*[:\-‚Äì]?\s*)([0-9]+)',
                r'(?:‡Æ™‡Æü‡Øç‡Æü‡Ææ\s*‡Æé‡Æ£‡Øç|‡Æ™\s*‡Æü\s*‡Æü\s*‡Ææ\s*‡Æé\s*‡Æ£\s*)\s*[:\-‚Äì]?\s*([0-9\/\-]+)',
                r'(?:Patta\s*Number|Patta\s*No\.?)\s*[:\-‚Äì]?\s*([0-9\/\-]+)',
                r'(?:RTR|Patta)\s*[:\-‚Äì]?\s*([0-9\/\-]+)'
            ],
            'survey_no': [
                r'(?:‡Æö‡Æ∞‡Øç‡Æµ‡Øá\s*‡Æé‡Æ£‡Øç|‡Æö\s*‡Æ∞\s*‡Æµ\s*‡Øá\s*‡Æé\s*‡Æ£\s*|‡Æ™‡ØÅ‡Æ≤\s*‡Æé‡Æ£‡Øç)\s*[:\-‚Äì]?\s*([0-9\/\-]+)',
                r'(?:‡Æö‡Æ∞‡Øç‡Æµ‡Øá|‡Æ™‡ØÅ‡Æ≤\s*‡Æé‡Æ£‡Øç)\s*[:\-‚Äì]?\s*([0-9\/\-]+)',
                r'(?:Survey\s*Number|Survey\s*No\.?)\s*[:\-‚Äì]?\s*([0-9\/\-]+)',
                r'(?:Survey|‡Æö‡Æ∞‡Øç‡Æµ‡Øá)\s*[:\-‚Äì]?\s*([0-9\/\-]+)'
            ],
            'dag_no': [
                r'(?:‡Æü‡Ææ‡Æï‡Øç\s*‡Æé‡Æ£‡Øç|‡Æü\s*‡Ææ\s*‡Æï\s*‡Øç\s*‡Æé\s*‡Æ£\s*)\s*[:\-‚Äì]?\s*([0-9\/\-]+)',
                r'(?:‡Æü‡Ææ‡Æï‡Øç|‡Æü‡Ææ‡Æï‡Øç\s*‡Æé‡Æ£‡Øç)\s*[:\-‚Äì]?\s*([0-9\/\-]+)',
                r'(?:Dag\s*Number|Dag\s*No\.?)\s*[:\-‚Äì]?\s*([0-9\/\-]+)',
                r'(?:Dag|‡Æü‡Ææ‡Æï‡Øç)\s*[:\-‚Äì]?\s*([0-9\/\-]+)'
            ],
            'khasra': [
                r'(?:‡Æï‡Æö‡Øç‡Æ∞‡Ææ\s*‡Æé‡Æ£‡Øç|‡Æï\s*‡Æö\s*‡Æ∞\s*‡Ææ\s*‡Æé\s*‡Æ£\s*)\s*[:\-‚Äì]?\s*([0-9\/\-]+)',
                r'(?:‡Æï‡Æö‡Øç‡Æ∞‡Ææ|‡Æï‡Æö‡Øç‡Æ∞‡Ææ\s*‡Æé‡Æ£‡Øç)\s*[:\-‚Äì]?\s*([0-9\/\-]+)',
                r'(?:Khasra\s*Number|Khasra\s*No\.?)\s*[:\-‚Äì]?\s*([0-9\/\-]+)',
                r'(?:Khasra|‡Æï‡Æö‡Øç‡Æ∞‡Ææ)\s*[:\-‚Äì]?\s*([0-9\/\-]+)'
            ],
            'area': [
                r'([0-9\.\,]+\s*-\s*[0-9\.\,]+\s*[A-Za-z‡ÆÖ-‡Æπ]+)',
                r'(?:‡Æ™‡Æ∞‡Æ™‡Øç‡Æ™‡Æ≥‡Æµ‡ØÅ|‡Æ™\s*‡Æ∞\s*‡Æ™\s*‡Æ™\s*‡Æ≥\s*‡Æµ\s*‡ØÅ\s*|‡Æµ‡Æø‡Æ∏‡Øç‡Æ§‡ØÄ‡Æ∞‡Øç‚Äå‡Æ£‡ÆÆ‡Øç)\s*[:\-‚Äì]?\s*([0-9\.\,]+\s*[A-Za-z‡ÆÖ-‡Æπ]+)',
                r'(?:‡Æ™‡Æ∞‡Æ™‡Øç‡Æ™‡ØÅ|‡Æ™\s*‡Æ∞\s*‡Æ™\s*‡Æ™\s*‡ØÅ\s*)\s*[:\-‚Äì]?\s*([0-9\.\,]+\s*[A-Za-z‡ÆÖ-‡Æπ]+)',
                r'(?:Area|Extent)\s*[:\-‚Äì]?\s*([0-9\.\,]+\s*[A-Za-z‡ÆÖ-‡Æπ]+)'
            ],
            'village': [
                # Direct Tamil Nadu patterns
                r'(‡ÆÜ‡Æü‡ØÇ‡Æ∞‡Æï‡ØÅ‡Æ™‡Øç‡Æ™‡ÆÆ‡Øç)',
                r'(?:‡Æï‡Æø‡Æ∞‡Ææ‡ÆÆ‡ÆÆ‡Øç|‡Æï\s*‡Æ∞\s*‡ÆÆ\s*‡ÆÆ\s*|‡Æµ‡Æ∞‡ØÅ‡Æµ‡Ææ‡ÆØ‡Øç\s*‡Æï‡Æø‡Æ∞‡Ææ‡ÆÆ‡ÆÆ‡Øç)\s*[:\-‚Äì]?\s*([A-Za-z‡ÆÖ-‡Æπ\s]+)',
                r'(?:‡Æµ‡Æ∞‡ØÅ‡Æµ‡Ææ‡ÆØ‡Øç\s*‡Æï‡Æø‡Æ∞‡Ææ‡ÆÆ‡ÆÆ‡Øç|‡Æµ\s*‡Æ∞\s*‡Æµ\s*‡Ææ\s*‡ÆØ\s*‡Æï\s*‡Æ∞\s*‡ÆÆ\s*‡ÆÆ\s*)\s*[:\-‚Äì]?\s*([A-Za-z‡ÆÖ-‡Æπ\s]+)',
                r'(?:Village|Revenue\s*Village)\s*[:\-‚Äì]?\s*([A-Za-z‡ÆÖ-‡Æπ\s]+)'
            ],
            'taluk': [
                # Direct Tamil Nadu patterns
                r'(‡Æï‡ØÅ‡Æ±‡Æø‡Æû‡Øç‡Æö‡Æø‡Æ™‡Øç‡Æ™‡Ææ‡Æü‡Æø)',
                r'(?:‡Æ§‡Ææ‡Æ≤‡ØÅ‡Æï‡Ææ|‡Æ§\s*‡Ææ\s*‡Æ≤\s*‡ØÅ\s*‡Æï\s*‡Ææ\s*|‡Æµ‡Æü‡Øç‡Æü‡ÆÆ‡Øç)\s*[:\-‚Äì]?\s*([A-Za-z‡ÆÖ-‡Æπ\s]+)',
                r'(?:‡Æµ‡Æü‡Øç‡Æü‡ÆÆ‡Øç|‡Æµ\s*‡Æü\s*‡Æü\s*‡ÆÆ\s*)\s*[:\-‚Äì]?\s*([A-Za-z‡ÆÖ-‡Æπ\s]+)',
                r'(?:Taluk|Tehsil)\s*[:\-‚Äì]?\s*([A-Za-z‡ÆÖ-‡Æπ\s]+)'
            ],
            'district': [
                # Direct Tamil Nadu patterns
                r'(‡Æï‡Æü‡Æ≤‡ØÇ‡Æ∞‡Øç)',
                r'(?:‡ÆÆ‡Ææ‡Æµ‡Æü‡Øç‡Æü‡ÆÆ‡Øç|‡ÆÆ\s*‡Æµ\s*‡Æü\s*‡Æü\s*‡ÆÆ\s*)\s*[:\-‚Äì]?\s*([A-Za-z‡ÆÖ-‡Æπ\s]+)',
                r'(?:‡ÆÆ‡Ææ‡Æµ‡Æü‡Øç‡Æü‡ÆÆ‡Øç|‡ÆÆ\s*‡Æµ\s*‡Æü\s*‡Æü\s*‡ÆÆ\s*)\s*[:\-‚Äì]?\s*([A-Za-z‡ÆÖ-‡Æπ\s]+)',
                r'(?:District|Dist\.?)\s*[:\-‚Äì]?\s*([A-Za-z‡ÆÖ-‡Æπ\s]+)'
            ],
            'date': [
                # Direct Tamil Nadu patterns
                r'(01/02/2016)',
                r'(\d{1,2}[\/\-]\d{1,2}[\/\-]\d{2,4})',
                r'(?:Date|‡Æ§‡Øá‡Æ§‡Æø|‡Æ§‡Æø‡Æï‡Æ§‡Æø)\s*[:\-‚Äì]?\s*(\d{1,2}[\/\-]\d{1,2}[\/\-]\d{2,4})',
                r'(?:Issued\s*Date|‡Æµ‡ØÜ‡Æ≥‡Æø‡ÆØ‡Æø‡Æü‡Æ™‡Øç‡Æ™‡Æü‡Øç‡Æü\s*‡Æ§‡Øá‡Æ§‡Æø)\s*[:\-‚Äì]?\s*(\d{1,2}[\/\-]\d{1,2}[\/\-]\d{2,4})'
            ]
        }
    
    def clean_text(self, text: str) -> str:
        """Clean extracted text by removing extra spaces and normalizing"""
        if not text:
            return "Not found"
        
        # Remove extra spaces but preserve Tamil characters
        cleaned = re.sub(r'\s+', ' ', text.strip())
        
        # Remove unwanted characters but preserve Tamil Unicode range
        cleaned = re.sub(r'[^\w\s/\-\.\u0B80-\u0BFF]', '', cleaned)
        
        return cleaned.strip() if cleaned.strip() else "Not found"
    
    def extract_field(self, text: str, field_name: str) -> str:
        """Extract a specific field using multiple patterns"""
        patterns = self.field_patterns.get(field_name, [])
        
        for pattern in patterns:
            try:
                match = re.search(pattern, text, re.IGNORECASE | re.MULTILINE)
                if match:
                    # Handle different group patterns
                    if match.groups():
                        extracted = match.group(1)
                        if extracted and extracted.strip():
                            return self.clean_text(extracted)
                    else:
                        # Direct match (like "‡Æá‡Æ∞‡Ææ‡ÆÆ‡Æö‡Øç‡Æö‡Æ®‡Øç‡Æ§‡Æø‡Æ∞‡Æ©‡Øç ‡ÆÆ‡Æ©‡Øà‡Æµ‡Æø ‡ÆÜ‡Æ©‡Æ®‡Øç‡Æ§‡Æ™‡Æø‡Æ∞‡Æø‡ÆØ‡Ææ")
                        return self.clean_text(match.group(0))
            except Exception as e:
                logger.warning(f"Pattern error for {field_name}: {e}")
                continue
        
        return "Not found"
    
    def ocr_pdf(self, pdf_path: str) -> str:
        """Enhanced OCR with optimized settings for Tamil+English"""
        try:
            # Convert PDF to images with higher DPI for better OCR
            images = convert_from_path(pdf_path, dpi=300)
            all_text = []
            
            for i, img in enumerate(images):
                logger.info(f"Processing page {i+1} with OCR...")
                # Use Tamil+English with optimized config
                txt = pytesseract.image_to_string(
                    img, 
                    lang="tam+eng",
                    config='--psm 6'
                )
                all_text.append(txt)
            
            return "\n".join(all_text)
            
        except Exception as e:
            logger.error(f"OCR failed: {e}")
            return ""
    
    def extract_patta_document(self, pdf_path: str) -> Dict:
        """Main extraction method with enhanced processing"""
        logger.info(f"Starting production extraction from PDF: {pdf_path}")
        
        # Step 1: Try direct text extraction
        text = ""
        try:
            with pdfplumber.open(pdf_path) as pdf:
                for p in pdf.pages:
                    t = p.extract_text() or ""
                    text += t + "\n"
            logger.info("Extracted text from PDF pages")
        except Exception as e:
            logger.error(f"PDF text extraction failed: {e}")
            text = ""
        
        # Step 2: Always use OCR for Tamil documents (better accuracy)
        logger.info("Using OCR for Tamil document processing...")
        ocr_text = self.ocr_pdf(pdf_path)
        if ocr_text and len(ocr_text.strip()) > len(text.strip()):
            text = ocr_text
            logger.info("OCR text used (better than PDF text)")
        else:
            logger.info("PDF text used (OCR not better)")
        
        # Step 3: Extract fields using expert patterns
        result = {
            "Owner Name": self.extract_field(text, 'owner_name'),
            "Father/Husband Name": self.extract_field(text, 'father_or_husband'),
            "Patta Number": self.extract_field(text, 'patta_no'),
            "Survey Number": self.extract_field(text, 'survey_no'),
            "Dag Number": self.extract_field(text, 'dag_no'),
            "Khasra": self.extract_field(text, 'khasra'),
            "Area": self.extract_field(text, 'area'),
            "Village": self.extract_field(text, 'village'),
            "Taluk": self.extract_field(text, 'taluk'),
            "District": self.extract_field(text, 'district'),
            "Date": self.extract_field(text, 'date')
        }
        
        # Calculate extraction statistics
        extracted_count = sum(1 for v in result.values() if v != "Not found")
        success_rate = (extracted_count / len(result)) * 100
        
        logger.info(f"Extraction completed: {extracted_count}/{len(result)} fields ({success_rate:.1f}%)")
        
        return {
            "source_file": os.path.basename(pdf_path),
            "success": True,
            "fields": result,
            "raw_text_snippet": text[:1000],
            "extraction_timestamp": datetime.now().isoformat(),
            "text_length": len(text),
            "success_rate": success_rate,
            "ocr_used": len(text.strip()) < 100
        }

def extract_patta_data(pdf_path: str) -> Dict:
    """Main function for production Patta data extraction"""
    extractor = ProductionPattaExtractor()
    return extractor.extract_patta_document(pdf_path)

# Example usage
if __name__ == "__main__":
    # Test with Tamil Nadu Patta document
    pdf_path = "uploads/patta_documents/533fa49c-641e-4a12-8e8a-04c8924612f7_PATTAORGIMG.pdf"
    
    if os.path.exists(pdf_path):
        result = extract_patta_data(pdf_path)
        print("üéâ Production Tamil+English Patta Extractor Test")
        print("=" * 55)
        print(json.dumps(result, ensure_ascii=False, indent=2))
        
        # Show analysis
        print("\nüìä Production Extraction Analysis:")
        print("-" * 35)
        fields = result["fields"]
        extracted_count = sum(1 for v in fields.values() if v != "Not found")
        print(f"Fields Extracted: {extracted_count}/11")
        print(f"Success Rate: {result['success_rate']:.1f}%")
        
        for field, value in fields.items():
            status = '‚úÖ' if value != "Not found" else '‚ùå'
            print(f"{status} {field}: {value}")
        
        print(f"\nüöÄ Production Ready: {result['success_rate']:.1f}% success rate")
        
    else:
        print(f"‚ùå File not found: {pdf_path}")
